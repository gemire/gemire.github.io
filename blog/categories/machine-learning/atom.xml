<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Machine-learning | gemire's space]]></title>
  <link href="http://hengzhang.me/blog/categories/machine-learning/atom.xml" rel="self"/>
  <link href="http://hengzhang.me/"/>
  <updated>2016-02-20T13:25:25+08:00</updated>
  <id>http://hengzhang.me/</id>
  <author>
    <name><![CDATA[gemire]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[机器学习之Gradient Boosted Regression Trees]]></title>
    <link href="http://hengzhang.me/machine-learning/2015/04/10/Machine-Learning-Gradient-Boosted-Regression-Tree/"/>
    <updated>2015-04-10T10:25:00+08:00</updated>
    <id>http://hengzhang.me/machine-learning/2015/04/10/Machine-Learning-Gradient-Boosted-Regression-Tree</id>
    <content type="html"><![CDATA[<p>实验室在做一个电力相关的大数据项目。现在项目的需求是做一个回归，用来预测温度，湿度和泄露电流之间的关系。数据的格式如下：
<code>
    8.0   184.0  143.0
    62.0  49.86  95.0
    12.0  180.0  144.0s
    0.0   0.0    197.0
    8.0   184.0  143.0
</code></p>

<p>数据的格式一目了然，然而数据的量挺大的，没有清洗之前有400万条，其实也算不上大数据啦。</p>

<p>刚开始本来打算用Hadoop集群上面的Mahout来做，后来看了官方的文档，发现Mahout里面相关的分类算法都是和分类相关的，一定要一个categories参数，于是就否决了Mahout,准备自己用Python来写。
 <!--more--></p>

<p>本来以为很简单的， 做一个最小二乘，拟合一下就可以得出结果，没想到结果出来很差，相关系数比较低。老师一句话就否决了我这个模型：<strong>线性模型肯定不行的啦</strong>。既然线性模型不行，那就寻找非线性的呗。</p>

<p>刚开始考虑用SVM做回归，后来发现在数据量比较大的情况下，其运算的时间复杂度比较高，于是请教实验室的师姐，师姐推荐用随机森林来做。随机森林算法的本质是本质是构建一个树型分类器{hk (x), k＝1，&hellip;}的集合，然后使用该集合通过投票进行分类和预测。后来又发现我们这个特征实在太少，就两个，随机森林的特点是随机选取特征，在我们的数据集里面随机性就无处可用。师姐后来又提到了树回归，于是后来就找到了GBRT(Gradient Boosted Regression Trees)。经过反复的参数调整，最终得到了不错的效果。关于GBRT参数的tuning,可以参考这个<a href="https://www.youtube.com/watch?v=-5l3g91NZfQ">演讲</a>(梯子自备)。</p>

<pre><code class="python">
__author__ = 'gemire'
import numpy as np
import matplotlib.pyplot as plt

from sklearn import preprocessing
from sklearn import datasets
from sklearn.utils import shuffle
from sklearn import ensemble
from sklearn.metrics import mean_squared_error

# load data function
def loadDataSet(fileName):
    numFeat = len(open(fileName).readline().split('\x01'))-1
    print(numFeat)
    dataMat = []
    labelMat = []
    fr = open(fileName)
    for line in fr.readlines():
        lineArr = []
        curLine = line.strip().split('\x01')
        for i in range(numFeat):
            lineArr.append(float(curLine[i]))
        dataMat.append(lineArr)
        labelMat.append(float(curLine[-1]))
    return dataMat,labelMat

#load Data
xArr,yArr = loadDataSet("full.txt")
xArr = np.array(xArr)
min_max_scaler = preprocessing.MinMaxScaler()
X = min_max_scaler.fit_transform(xArr)
y = np.array(yArr)

print(X.shape,y.shape)

X = X.astype(np.float32)
offset = int(X.shape[0] * .8)
X_train, y_train = X[:offset], y[:offset]
X_test, y_test = X[offset:], y[offset:]

# fit regression model
params = {'n_estimators':500, 'max_depth':4, 'min_samples_split':2,
          'learning_rate':0.1, 'loss':'ls'}
gbr = ensemble.GradientBoostingRegressor(**params)

gbr.fit(X_train, y_train)
mse = mean_squared_error(y_test, gbr.predict(X_test))
print("MSE: %.4f" % mse)
print(np.corrcoef(y_test,gbr.predict(X_test)))
print(np.corrcoef(y,gbr.predict(X)))
# plot training deviance

# compute test set deviance
test_score = np.zeros((params['n_estimators'],), dtype=np.float64)

for i, y_pred in enumerate(gbr.staged_decision_function(X_test)):
    test_score[i] = gbr.loss_(y_test, y_pred)

plt.figure()
plt.subplot(1, 1, 1)
plt.title('Deviance')
plt.plot(np.arange(params['n_estimators']) + 1,
         gbr.train_score_, 'b-',
         label='Training Set Deviance')
plt.plot(np.arange(params['n_estimators']) + 1,
         test_score, 'r-',
         label='Test Set Deviance')
plt.legend(loc='upper right')
plt.xlabel('Boosting Iterations')
plt.ylabel('Deviance')
plt.show()
</code></pre>
]]></content>
  </entry>
  
</feed>
